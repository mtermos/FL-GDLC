{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_class: false\n",
      "with_network_features: false\n",
      "n_clients: 5\n",
      "n_rounds: 20\n",
      "config_fit:\n",
      "  lr: 0.01\n",
      "  momentum: 0.9\n",
      "  local_epochs: 1\n",
      "  batch_size: 256\n",
      "\n",
      "dataset: cic_ton_iot\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from logging import INFO, DEBUG\n",
    "from flwr.common.logger import log\n",
    "\n",
    "\n",
    "from src.models.evaluation_metrics import custom_acc_mc, custom_acc_binary\n",
    "\n",
    "from src.data.dataset_info import datasets\n",
    "\n",
    "with initialize(version_base=None, config_path=\"conf/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "# choosing the dataset\n",
    "dataset = datasets[0]\n",
    "print(\"dataset: {}\".format(dataset.name))\n",
    "folder_path = \"./fl_from_2_datasets_pca/\"\n",
    "\n",
    "learning_rate = 0.001\n",
    "LAMBD_1 = 0.0001\n",
    "LAMBD_2 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240720-163506'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "dtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_paths = [\n",
    "    #folder_path + \"client_0_pca.parquet\",\n",
    "    #folder_path + \"client_1_pca.parquet\",\n",
    "    folder_path + \"client_2_pca.parquet\",\n",
    "    folder_path + \"client_3_pca.parquet\",\n",
    "    folder_path + \"client_4_pca.parquet\",\n",
    "    folder_path + \"client_5_pca.parquet\",\n",
    "    #folder_path + \"client_6_pca.parquet\",\n",
    "    #folder_path + \"client_7_pca.parquet\"\n",
    "]\n",
    "\n",
    "cn_2 = [\n",
    "    \"dst_global_betweenness\",\n",
    "    \"src_global_degree\",\n",
    "    \"dst_global_degree\",\n",
    "    \"src_mv\",\n",
    "    \"src_global_pagerank\",\n",
    "    \"dst_global_pagerank\",\n",
    "    \"src_global_betweenness\",\n",
    "    \"dst_mv\"\n",
    "]\n",
    "\n",
    "cn_1 = [\n",
    "    \"dst_local_pagerank\",\n",
    "    \"src_local_betweenness\",\n",
    "    \"src_Comm\",\n",
    "    \"src_local_degree\",\n",
    "    \"dst_local_betweenness\",\n",
    "    \"dst_Comm\",\n",
    "    \"dst_local_degree\",\n",
    "    \"src_local_pagerank\"\n",
    "]\n",
    "\n",
    "for i, client_path in enumerate(clients_paths):\n",
    "    # Determine which set of columns to drop based on the client index\n",
    "    if i < 5:\n",
    "        drop_columns = cn_2\n",
    "    else:\n",
    "        drop_columns = cn_1\n",
    "    df = pd.read_parquet(client_path)\n",
    "    df.drop(columns=drop_columns, errors='ignore', inplace=True)\n",
    "test = pd.read_parquet(folder_path + \"test.parquet\")\n",
    "df.drop(columns=cn_2, errors='ignore', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in columns for client 0: set()\n",
      "Difference in columns for client 1: set()\n",
      "Difference in columns for client 2: set()\n",
      "Difference in columns for client 3: set()\n"
     ]
    }
   ],
   "source": [
    "client_columns = []\n",
    "\n",
    "# Read each file and store the columns as a set\n",
    "for client_path in clients_paths:\n",
    "    df = pd.read_parquet(client_path)\n",
    "    client_columns.append(set(df.columns))\n",
    "\n",
    "# Find the intersection of columns across all clients\n",
    "common_columns = set.intersection(*client_columns)\n",
    "\n",
    "# Find the difference of columns for each client compared to the intersection\n",
    "differences = [columns - common_columns for columns in client_columns]\n",
    "\n",
    "# Display the columns of each client, the intersection, and the differences\n",
    "#for idx, columns in enumerate(client_columns):\n",
    " #   print(f\"Client {idx} columns: {columns}\")\n",
    "\n",
    "#print(f\"\\nIntersection of columns across all clients: {common_columns}\")\n",
    "\n",
    "for idx, diff in enumerate(differences):\n",
    "    print(f\"Difference in columns for client {idx}: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ACK Flag Cnt',\n",
       "  'Active Max',\n",
       "  'Active Mean',\n",
       "  'Active Min',\n",
       "  'Active Std',\n",
       "  'Attack',\n",
       "  'Bwd Blk Rate Avg',\n",
       "  'Bwd Byts/b Avg',\n",
       "  'Bwd Header Len',\n",
       "  'Bwd IAT Max',\n",
       "  'Bwd IAT Mean',\n",
       "  'Bwd IAT Min',\n",
       "  'Bwd IAT Std',\n",
       "  'Bwd IAT Tot',\n",
       "  'Bwd PSH Flags',\n",
       "  'Bwd Pkt Len Max',\n",
       "  'Bwd Pkt Len Mean',\n",
       "  'Bwd Pkt Len Min',\n",
       "  'Bwd Pkt Len Std',\n",
       "  'Bwd Pkts/b Avg',\n",
       "  'Bwd Pkts/s',\n",
       "  'Bwd Seg Size Avg',\n",
       "  'Bwd URG Flags',\n",
       "  'CWE Flag Count',\n",
       "  'Class',\n",
       "  'Down/Up Ratio',\n",
       "  'Dst IP',\n",
       "  'Dst Port',\n",
       "  'ECE Flag Cnt',\n",
       "  'FIN Flag Cnt',\n",
       "  'Flow Byts/s',\n",
       "  'Flow Duration',\n",
       "  'Flow IAT Max',\n",
       "  'Flow IAT Mean',\n",
       "  'Flow IAT Min',\n",
       "  'Flow IAT Std',\n",
       "  'Flow ID',\n",
       "  'Flow Pkts/s',\n",
       "  'Fwd Act Data Pkts',\n",
       "  'Fwd Blk Rate Avg',\n",
       "  'Fwd Byts/b Avg',\n",
       "  'Fwd Header Len',\n",
       "  'Fwd IAT Max',\n",
       "  'Fwd IAT Mean',\n",
       "  'Fwd IAT Min',\n",
       "  'Fwd IAT Tot',\n",
       "  'Fwd PSH Flags',\n",
       "  'Fwd Pkt Len Max',\n",
       "  'Fwd Pkt Len Mean',\n",
       "  'Fwd Pkt Len Min',\n",
       "  'Fwd Pkt Len Std',\n",
       "  'Fwd Pkts/b Avg',\n",
       "  'Fwd Pkts/s',\n",
       "  'Fwd Seg Size Avg',\n",
       "  'Fwd Seg Size Min',\n",
       "  'Fwd URG Flags',\n",
       "  'Idle Max',\n",
       "  'Idle Mean',\n",
       "  'Idle Min',\n",
       "  'Idle Std',\n",
       "  'Init Bwd Win Byts',\n",
       "  'Init Fwd Win Byts',\n",
       "  'Label',\n",
       "  'PSH Flag Cnt',\n",
       "  'Pkt Len Max',\n",
       "  'Pkt Len Mean',\n",
       "  'Pkt Len Min',\n",
       "  'Pkt Len Std',\n",
       "  'Pkt Len Var',\n",
       "  'Pkt Size Avg',\n",
       "  'Protocol',\n",
       "  'RST Flag Cnt',\n",
       "  'SYN Flag Cnt',\n",
       "  'Src IP',\n",
       "  'Src Port',\n",
       "  'Subflow Bwd Byts',\n",
       "  'Subflow Bwd Pkts',\n",
       "  'Subflow Fwd Byts',\n",
       "  'Subflow Fwd Pkts',\n",
       "  'Timestamp',\n",
       "  'Tot Bwd Pkts',\n",
       "  'Tot Fwd Pkts',\n",
       "  'TotLen Bwd Pkts',\n",
       "  'TotLen Fwd Pkts',\n",
       "  'URG Flag Cnt',\n",
       "  'dst_betweenness',\n",
       "  'dst_closeness',\n",
       "  'dst_degree',\n",
       "  'dst_eigenvector',\n",
       "  'dst_k_core',\n",
       "  'dst_k_truss',\n",
       "  'dst_pagerank',\n",
       "  'pca_1',\n",
       "  'pca_2',\n",
       "  'src_betweenness',\n",
       "  'src_closeness',\n",
       "  'src_degree',\n",
       "  'src_eigenvector',\n",
       "  'src_k_core',\n",
       "  'src_k_truss',\n",
       "  'src_pagerank'},\n",
       " {'client_0_pca': {'dst_multidigraph_betweenness',\n",
       "   'dst_multidigraph_degree',\n",
       "   'dst_multidigraph_pagerank',\n",
       "   'src_multidigraph_betweenness',\n",
       "   'src_multidigraph_degree',\n",
       "   'src_multidigraph_pagerank'},\n",
       "  'client_1_pca': set(),\n",
       "  'client_2_pca': set(),\n",
       "  'client_3_pca': set(),\n",
       "  'client_4_pca': set(),\n",
       "  'client_5_pca': set(),\n",
       "  'client_6_pca': set(),\n",
       "  'client_7_pca': set(),\n",
       "  'test': set()})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clients_pathss = [\n",
    "    folder_path + \"client_0_pca.parquet\",\n",
    "    folder_path + \"client_1_pca.parquet\",\n",
    "    folder_path + \"client_2_pca.parquet\",\n",
    "    folder_path + \"client_3_pca.parquet\",\n",
    "    folder_path + \"client_4_pca.parquet\",\n",
    "    folder_path + \"client_5_pca.parquet\",\n",
    "    folder_path + \"client_6_pca.parquet\",\n",
    "    folder_path + \"client_7_pca.parquet\",\n",
    "    folder_path + \"test.parquet\"\n",
    "]\n",
    "\n",
    "columns_per_client = {}\n",
    "for path in clients_pathss:\n",
    "    client_name = path.split('/')[-1].split('.')[0]  \n",
    "    df = pd.read_parquet(path)\n",
    "    columns_per_client[client_name] = set(df.columns)\n",
    "\n",
    "all_features = set().union(*columns_per_client.values())\n",
    "common_features = set.intersection(*columns_per_client.values())\n",
    "unique_features = {client: columns - common_features for client, columns in columns_per_client.items()}\n",
    "\n",
    "common_features, unique_features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> classes_set: {'benign', 'attack'}\n",
      "==>> num_classes: 2\n",
      "==>> labels_names: {0: 'benign', 1: 'attack'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# the input dimension of the training set\n",
    "# input_dim = df.shape[1] - len(drop_columns) - len(weak_columns) - 1  # for the label_column\n",
    "  \n",
    "# specifying the number of classes, since it is different from one dataset to another and also if binary or multi-class classification\n",
    "classes_set = {\"benign\", \"attack\"}\n",
    "labels_names = {0: \"benign\", 1: \"attack\"}\n",
    "num_classes = 2\n",
    "if cfg.multi_class:\n",
    "    with open(folder_path + \"labels_names.pkl\", 'rb') as f:\n",
    "        labels_names, classes_set = pickle.load(f)\n",
    "    num_classes = len(classes_set)\n",
    "    \n",
    "labels_names = {int(k): v for k, v in labels_names.items()}\n",
    "\n",
    "print(f\"==>> classes_set: {classes_set}\")\n",
    "print(f\"==>> num_classes: {num_classes}\")\n",
    "print(f\"==>> labels_names: {labels_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol',\n",
      "       'Timestamp', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts',\n",
      "       ...\n",
      "       'src_closeness', 'dst_closeness', 'src_pagerank', 'dst_pagerank',\n",
      "       'src_k_core', 'dst_k_core', 'src_k_truss', 'dst_k_truss', 'pca_1',\n",
      "       'pca_2'],\n",
      "      dtype='object', length=101)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_parquet(folder_path + \"test.parquet\")\n",
    "print(test.columns)\n",
    "if cfg.multi_class:\n",
    "    test[dataset.label_col] = test[dataset.class_num_col]\n",
    "    \n",
    "#test.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\n",
    "#test.drop([\"src_multidigraph_degree\", \"dst_multidigraph_degree\", \"src_multidigraph_betweenness\", \"dst_multidigraph_betweenness\", \"src_multidigraph_pagerank\", \"dst_multidigraph_pagerank\"], axis=1, inplace=True)\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    test_by_class = {}\n",
    "    classes = test[dataset.class_col].unique()\n",
    "    for class_value in classes:\n",
    "        test_class = test[test[dataset.class_col] == class_value].copy()\n",
    "        test_class.drop(dataset.drop_columns, axis=1, inplace=True, errors='ignore')\n",
    "        test_class.drop(dataset.weak_columns, axis=1, inplace=True, errors='ignore')\n",
    "        test_class.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        test_class_labels = test_class[dataset.label_col].to_numpy()\n",
    "        test_class = test_class.drop([dataset.label_col], axis=1).to_numpy()\n",
    "\n",
    "        test_by_class[class_value] = (test_class, test_class_labels)\n",
    "    \n",
    "    \n",
    "test.drop(dataset.drop_columns, axis=1, inplace=True,errors='ignore')\n",
    "test.drop(dataset.weak_columns, axis=1, inplace=True,errors='ignore')\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "  \n",
    "test_labels = test[dataset.label_col].to_numpy()\n",
    "test = test.drop([dataset.label_col], axis=1).to_numpy()\n",
    "input_dim = test.shape[1]\n",
    "client_data = []\n",
    "for client_path in clients_paths:\n",
    "    client_data.append(pd.read_parquet(client_path))\n",
    "    \n",
    "for i in range(len(client_data)):\n",
    "    \n",
    "    cdata = client_data[i]\n",
    "\n",
    "    if cfg.multi_class:\n",
    "        cdata[dataset.label_col] = cdata[dataset.class_num_col]\n",
    "        \n",
    "    #cdata.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\n",
    "    #if i==0:\n",
    "    cdata.drop([\"src_multidigraph_degree\", \"dst_multidigraph_degree\", \"src_multidigraph_betweenness\", \"dst_multidigraph_betweenness\", \"src_multidigraph_pagerank\", \"dst_multidigraph_pagerank\"], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    cdata.drop(dataset.drop_columns, axis=1, inplace=True, errors='ignore')\n",
    "    cdata.drop(dataset.weak_columns, axis=1, inplace=True, errors='ignore')\n",
    "    cdata.reset_index(drop=True, inplace=True)\n",
    "    c_train, c_test = train_test_split(cdata, test_size=0.1)\n",
    "\n",
    "    y_train = c_train[dataset.label_col].to_numpy()\n",
    "    x_train = c_train.drop([dataset.label_col], axis=1).to_numpy()\n",
    "    y_test = c_test[dataset.label_col].to_numpy()\n",
    "    x_test = c_test.drop([dataset.label_col], axis=1).to_numpy()\n",
    "\n",
    "    client_data[i] = (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, Input, regularizers, callbacks, metrics, optimizers, initializers\n",
    "# from src.models.evaluation_metrics import f1_m\n",
    "\n",
    "def create_keras_model(input_shape, alpha = learning_rate):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv1D(80, kernel_size=5,\n",
    "                activation=\"relu\", input_shape=(input_shape, 1), kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2)))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    \n",
    "    model.add(layers.Conv1D(80, 5, activation='relu', kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2)))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    \n",
    "    model.add(layers.LSTM(units=80,\n",
    "                            kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2),\n",
    "                            recurrent_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2),\n",
    "                            bias_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2),\n",
    "                            return_sequences=False,\n",
    "                            ))\n",
    "\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dense(500,activation='relu', kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dense(200,activation='relu', kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dense(80,activation='relu', kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "\n",
    "    if cfg.multi_class:\n",
    "        model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=alpha),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    else:\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=alpha),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │            \u001b[38;5;34m34\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │        \u001b[38;5;34m32,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m80\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m80\u001b[0m)          │            \u001b[38;5;34m12\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │        \u001b[38;5;34m51,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │        \u001b[38;5;34m40,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │         \u001b[38;5;34m1,000\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m100,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │        \u001b[38;5;34m16,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m81\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242,707</span> (948.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m242,707\u001b[0m (948.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242,707</span> (948.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m242,707\u001b[0m (948.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_keras_model(input_dim)\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FL settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = {}\n",
    "results_final[\"baseline\"] = {}\n",
    "results_final[\"baseline\"][\"accuracy\"] = {}\n",
    "results_final[\"baseline\"][\"f1s\"] = {}\n",
    "\n",
    "results_final[\"centralities - DiGraph\"] = {}\n",
    "results_final[\"centralities - DiGraph\"][\"accuracy\"] = {}\n",
    "results_final[\"centralities - DiGraph\"][\"f1s\"] = {}\n",
    "\n",
    "results_final[\"centralities - MultiDiGraph\"] = {}\n",
    "results_final[\"centralities - MultiDiGraph\"][\"accuracy\"] = {}\n",
    "results_final[\"centralities - MultiDiGraph\"][\"f1s\"] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configuration': '2dt - baseline',\n",
       " 'dtime': '20240720-163506',\n",
       " 'multi_class': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'dataset_name': 'cic_ton_iot',\n",
       " 'num_classes': 2,\n",
       " 'labels_names': {0: 'benign', 1: 'attack'},\n",
       " 'input_dim': 39,\n",
       " 'scores': {'server': {},\n",
       "  'clients': {},\n",
       "  'accuracy': {},\n",
       "  'f1s': {},\n",
       "  'test_by_class': {'accuracy': {'Benign': {},\n",
       "    'DoS Hulk': {},\n",
       "    'PortScan': {},\n",
       "    'ddos': {},\n",
       "    'DoS slowloris': {},\n",
       "    'DoS Slowhttptest': {},\n",
       "    'FTP-Patator': {},\n",
       "    'DoS GoldenEye': {},\n",
       "    'SSH-Patator': {},\n",
       "    'Bot': {},\n",
       "    'xss': {},\n",
       "    'bruteforce': {}},\n",
       "   'f1s': {'Benign': {},\n",
       "    'DoS Hulk': {},\n",
       "    'PortScan': {},\n",
       "    'ddos': {},\n",
       "    'DoS slowloris': {},\n",
       "    'DoS Slowhttptest': {},\n",
       "    'FTP-Patator': {},\n",
       "    'DoS GoldenEye': {},\n",
       "    'SSH-Patator': {},\n",
       "    'Bot': {},\n",
       "    'xss': {},\n",
       "    'bruteforce': {}},\n",
       "   'length': 446}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}  # a dictionary that will contain all the options and results of models\n",
    "# add all options to the results dictionary, to know what options selected for obtained results\n",
    "results[\"configuration\"] = \"2dt - baseline\"\n",
    "results[\"dtime\"] = dtime\n",
    "results[\"multi_class\"] = cfg.multi_class\n",
    "results[\"learning_rate\"] = learning_rate\n",
    "results[\"dataset_name\"] = dataset.name\n",
    "results[\"num_classes\"] = num_classes\n",
    "results[\"labels_names\"] = labels_names\n",
    "results[\"input_dim\"] = input_dim\n",
    "\n",
    "results[\"scores\"] = {}\n",
    "results[\"scores\"][\"server\"] = {}\n",
    "results[\"scores\"][\"clients\"] = {}\n",
    "results[\"scores\"][\"accuracy\"] = {}\n",
    "results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    results[\"scores\"][\"test_by_class\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "    for k in test_by_class.keys():\n",
    "        results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, x_train, y_train, x_test, y_test):\n",
    "        self.cid = cid\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "        self.model = create_keras_model(input_shape=input_dim)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def set_parameters(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \n",
    "        lr=float(config[\"lr\"])\n",
    "        self.model = create_keras_model(input_shape=input_dim, alpha=lr)\n",
    "        self.set_parameters(parameters, config)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/baseline/client_{}\".format(dtime, self.cid)\n",
    "        tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        history = self.model.fit(self.x_train, self.y_train,\n",
    "                                 epochs=config[\"local_epochs\"],\n",
    "                                 batch_size=config[\"batch_size\"],\n",
    "                                 validation_data=(self.x_test, self.y_test),\n",
    "                                 verbose=0,\n",
    "                                 callbacks=[tensorboard_callback])\n",
    "\n",
    "        return self.get_parameters(config), len(self.x_train), {k: v[-1] for k, v in history.history.items()}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test, cfg.config_fit.batch_size, verbose=0)\n",
    "        return loss, len(self.x_test), {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn():\n",
    "    def client_fn(cid: str):\n",
    "        i = int(cid)\n",
    "        return FLClient(cid, client_data[i][0], client_data[i][1], client_data[i][2], client_data[i][3]).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_fit_config(config: DictConfig):\n",
    "\n",
    "    def fit_config_fn(server_round: int):\n",
    "        alpha = learning_rate\n",
    "        if server_round > 5:\n",
    "            alpha = alpha / (1 + 0.5 * server_round)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"lr\": alpha,\n",
    "            \"local_epochs\": config.local_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "        }\n",
    "\n",
    "    return fit_config_fn\n",
    "\n",
    "\n",
    "def get_evaluate_fn(x_test_sever, y_test_server):\n",
    "\n",
    "    def evaluate_fn(server_round: int, parameters, config):\n",
    "        # eval_model = model\n",
    "        eval_model = create_keras_model(input_shape=input_dim)\n",
    "        eval_model.set_weights(parameters)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/baseline/server\".format(dtime) \n",
    "        # logdir = \"logs/scalars/client{}_\".format(config[\"cid\"]) + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        test_loss, test_acc = eval_model.evaluate(x_test_sever, y_test_server,\n",
    "                                                  batch_size = cfg.config_fit.batch_size,\n",
    "                                                  callbacks=[tensorboard_callback])\n",
    "        \n",
    "        \n",
    "        y_pred = eval_model.predict(x_test_sever, batch_size = cfg.config_fit.batch_size)\n",
    "        \n",
    "        if cfg.multi_class:\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            scores = custom_acc_mc(y_test_server, y_pred)\n",
    "        else:\n",
    "            y_pred = np.transpose(y_pred)[0]\n",
    "            y_pred = list(\n",
    "                map(lambda x: 0 if x < 0.5 else 1, y_pred))\n",
    "            scores = custom_acc_binary(y_test_server, y_pred)\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        results_final[\"baseline\"][\"accuracy\"][server_round] = scores[\"accuracy\"]\n",
    "        results_final[\"baseline\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        \n",
    "        if not cfg.multi_class:\n",
    "            for k in test_by_class.keys():\n",
    "                y_pred_class = eval_model.predict(test_by_class[k][0], batch_size = cfg.config_fit.batch_size, verbose = 0)\n",
    "                y_pred_class = np.transpose(y_pred_class)[0]\n",
    "                y_pred_class = list(map(lambda x: 0 if x < 0.5 else 1, y_pred_class))\n",
    "                scores_class = custom_acc_binary(test_by_class[k][1], y_pred_class)\n",
    "                results[\"scores\"][\"test_by_class\"][\"accuracy\"][k][server_round] = scores_class[\"accuracy\"]\n",
    "                results[\"scores\"][\"test_by_class\"][\"f1s\"][k][server_round] = scores_class[\"f1s\"]\n",
    "                \n",
    "        log(INFO, f\"==>> scores: {scores}\")\n",
    "        \n",
    "        \n",
    "        return test_loss, {\"accuracy\": test_acc, \"f1s\": scores[\"f1s\"], \"FPR\": scores[\"FPR\"], \"FNR\": scores[\"FNR\"]}\n",
    "\n",
    "    return evaluate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics):\n",
    "    print(f\"==>> weighted_average: {metrics}\")\n",
    "\n",
    "    total_examples = 0\n",
    "    federated_metrics = {k: 0 for k in metrics[0][1].keys()}\n",
    "    for num_examples, m in metrics:\n",
    "        for k, v in m.items():\n",
    "            federated_metrics[k] += num_examples * v\n",
    "        total_examples += num_examples\n",
    "    return {k: v / total_examples for k, v in federated_metrics.items()}\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "    min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "    fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "    min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "    min_available_clients=len(client_data),  # total clients in the simulation\n",
    "    fit_metrics_aggregation_fn = weighted_average,\n",
    "    # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "    on_fit_config_fn=get_on_fit_config(\n",
    "        cfg.config_fit\n",
    "    ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "    evaluate_fn=get_evaluate_fn(test, test_labels),\n",
    ")  # a function to run on the server side to evaluate the global model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FL Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-20 16:35:33,610 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "2024-07-20 16:35:40,347\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-07-20 16:35:43,647 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 32.0, 'node:__internal_head__': 1.0, 'node:127.0.0.1': 1.0, 'memory': 34389929166.0, 'object_store_memory': 17194964582.0}\n",
      "INFO flwr 2024-07-20 16:35:43,649 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-07-20 16:35:43,650 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.0}\n",
      "INFO flwr 2024-07-20 16:35:43,668 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "INFO flwr 2024-07-20 16:35:43,670 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-07-20 16:35:43,671 | server.py:276 | Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[36m(pid=15016)\u001b[0m 2024-07-20 16:35:45.873407: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15100)\u001b[0m c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15100)\u001b[0m   super().__init__(\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15100)\u001b[0m 2024-07-20 16:35:50.332956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15100)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO flwr 2024-07-20 16:35:50,637 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-07-20 16:35:50,639 | server.py:91 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 28ms/step - accuracy: 0.4223 - loss: 3.1230\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-20 16:38:41,218 | 589012468.py:68 | ==>> scores: {'accuracy': 0.42202847652193215, 'recall': 0.42202847652193215, 'precision': 0.5485151163593502, 'f1s': 0.416052114953504, 'FPR': 0.7070546773561963, 'FNR': 0.3121115281761456, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.66      0.29      0.41    339647\\n           1       0.32      0.69      0.44    164909\\n\\n    accuracy                           0.42    504556\\n   macro avg       0.49      0.49      0.42    504556\\nweighted avg       0.55      0.42      0.42    504556\\n'}\n",
      "INFO flwr 2024-07-20 16:38:41,227 | server.py:94 | initial parameters (loss, other metrics): 3.124509572982788, {'accuracy': 0.42202848196029663, 'f1s': 0.416052114953504, 'FPR': 0.7070546773561963, 'FNR': 0.3121115281761456}\n",
      "INFO flwr 2024-07-20 16:38:41,228 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-07-20 16:38:41,230 | server.py:222 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
      "\u001b[2m\u001b[36m(pid=15032)\u001b[0m 2024-07-20 16:35:47.106517: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15032)\u001b[0m c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15032)\u001b[0m   super().__init__(\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15032)\u001b[0m 2024-07-20 16:38:42.392355: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15032)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15016)\u001b[0m c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15016)\u001b[0m   super().__init__(\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15016)\u001b[0m 2024-07-20 16:38:42.835606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=15016)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "DEBUG flwr 2024-07-20 16:40:00,099 | server.py:236 | fit_round 1 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6253105401992798, 'loss': 1.1626622676849365, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.7399616241455078}), (489061, {'accuracy': 0.6272183060646057, 'loss': 1.2003849744796753, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.7423774600028992}), (489061, {'accuracy': 0.626463770866394, 'loss': 1.193687915802002, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.740676999092102}), (489061, {'accuracy': 0.6273736953735352, 'loss': 1.2229899168014526, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.7415419816970825})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 27ms/step - accuracy: 0.4956 - loss: 0.8002\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-20 16:42:48,687 | 589012468.py:68 | ==>> scores: {'accuracy': 0.4963274641466953, 'recall': 0.4963274641466953, 'precision': 0.5467694306287098, 'f1s': 0.5116518589793133, 'FPR': 0.48182377586140906, 'FNR': 0.548672298055291, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.66      0.52      0.58    339647\\n           1       0.31      0.45      0.37    164909\\n\\n    accuracy                           0.50    504556\\n   macro avg       0.49      0.48      0.48    504556\\nweighted avg       0.55      0.50      0.51    504556\\n'}\n",
      "INFO flwr 2024-07-20 16:42:48,697 | server.py:125 | fit progress: (1, 0.8000199794769287, {'accuracy': 0.4963274598121643, 'f1s': 0.5116518589793133, 'FPR': 0.48182377586140906, 'FNR': 0.548672298055291}, 247.4662854000926)\n",
      "INFO flwr 2024-07-20 16:42:48,699 | server.py:171 | evaluate_round 1: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 16:42:48,701 | server.py:222 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 16:44:10,156 | server.py:236 | fit_round 2 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6197120547294617, 'loss': 0.6807188987731934, 'val_accuracy': 0.5818811058998108, 'val_loss': 0.7166900634765625}), (489061, {'accuracy': 0.608533501625061, 'loss': 0.695033073425293, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6701779365539551}), (489061, {'accuracy': 0.6250508427619934, 'loss': 0.6840630769729614, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6736971139907837}), (489061, {'accuracy': 0.6177143454551697, 'loss': 0.6834655404090881, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6824718117713928})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 27ms/step - accuracy: 0.3263 - loss: 0.8277\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 16:47:00,382 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3268398354196561, 'recall': 0.3268398354196561, 'precision': 0.10682427801714788, 'f1s': 0.16102060725869183, 'FPR': 1.0, 'FNR': 0.0, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00    339647\\n           1       0.33      1.00      0.49    164909\\n\\n    accuracy                           0.33    504556\\n   macro avg       0.16      0.50      0.25    504556\\nweighted avg       0.11      0.33      0.16    504556\\n'}\n",
      "INFO flwr 2024-07-20 16:47:00,389 | server.py:125 | fit progress: (2, 0.8274058103561401, {'accuracy': 0.3268398344516754, 'f1s': 0.16102060725869183, 'FPR': 1.0, 'FNR': 0.0}, 499.15684810001403)\n",
      "INFO flwr 2024-07-20 16:47:00,391 | server.py:171 | evaluate_round 2: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 16:47:00,393 | server.py:222 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 16:48:35,214 | server.py:236 | fit_round 3 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6255661249160767, 'loss': 0.6755192875862122, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6708500981330872}), (489061, {'accuracy': 0.6202661991119385, 'loss': 0.6723750829696655, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6625652313232422}), (489061, {'accuracy': 0.6276885867118835, 'loss': 0.6678911447525024, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.685636579990387}), (489061, {'accuracy': 0.6264228820800781, 'loss': 0.6707073450088501, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6639322638511658})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 28ms/step - accuracy: 0.3272 - loss: 0.7541\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 16:51:23,671 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3276663046321915, 'recall': 0.3276663046321915, 'precision': 0.45535449610669826, 'f1s': 0.179989161923902, 'FPR': 0.98354762444538, 'FNR': 0.03135668762772196, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.52      0.02      0.03    339647\\n           1       0.32      0.97      0.49    164909\\n\\n    accuracy                           0.33    504556\\n   macro avg       0.42      0.49      0.26    504556\\nweighted avg       0.46      0.33      0.18    504556\\n'}\n",
      "INFO flwr 2024-07-20 16:51:23,680 | server.py:125 | fit progress: (3, 0.7539950609207153, {'accuracy': 0.327666312456131, 'f1s': 0.179989161923902, 'FPR': 0.98354762444538, 'FNR': 0.03135668762772196}, 762.4462385997176)\n",
      "INFO flwr 2024-07-20 16:51:23,682 | server.py:171 | evaluate_round 3: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 16:51:23,683 | server.py:222 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 16:52:53,897 | server.py:236 | fit_round 4 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6174240112304688, 'loss': 0.6830087304115295, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6761804819107056}), (489061, {'accuracy': 0.611882746219635, 'loss': 0.6780111789703369, 'val_accuracy': 0.5823411345481873, 'val_loss': 0.6874815225601196}), (489061, {'accuracy': 0.6264167428016663, 'loss': 0.665158212184906, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6653954386711121}), (489061, {'accuracy': 0.5996266603469849, 'loss': 0.6868315935134888, 'val_accuracy': 0.5818811058998108, 'val_loss': 0.7199954986572266})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 28ms/step - accuracy: 0.3535 - loss: 0.8617\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 16:55:41,861 | 589012468.py:68 | ==>> scores: {'accuracy': 0.35416484988782215, 'recall': 0.35416484988782215, 'precision': 0.6273121571133472, 'f1s': 0.233832939350527, 'FPR': 0.9422135334626833, 'FNR': 0.035413470459465524, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.77      0.06      0.11    339647\\n           1       0.33      0.96      0.49    164909\\n\\n    accuracy                           0.35    504556\\n   macro avg       0.55      0.51      0.30    504556\\nweighted avg       0.63      0.35      0.23    504556\\n'}\n",
      "INFO flwr 2024-07-20 16:55:41,871 | server.py:125 | fit progress: (4, 0.8613170981407166, {'accuracy': 0.35416483879089355, 'f1s': 0.233832939350527, 'FPR': 0.9422135334626833, 'FNR': 0.035413470459465524}, 1020.637093199417)\n",
      "INFO flwr 2024-07-20 16:55:41,873 | server.py:171 | evaluate_round 4: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 16:55:41,874 | server.py:222 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 16:57:14,779 | server.py:236 | fit_round 5 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6219510436058044, 'loss': 0.6752099394798279, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6608679890632629}), (489061, {'accuracy': 0.6251940131187439, 'loss': 0.6746762990951538, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6672102808952332}), (489061, {'accuracy': 0.6180844306945801, 'loss': 0.6759049892425537, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6630114316940308}), (489061, {'accuracy': 0.5838678479194641, 'loss': 0.6865887641906738, 'val_accuracy': 0.583684504032135, 'val_loss': 0.6838566660881042})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 33ms/step - accuracy: 0.3264 - loss: 0.8380\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:00:29,290 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3269508240908839, 'recall': 0.3269508240908839, 'precision': 0.7205984691584876, 'f1s': 0.16127681668486085, 'FPR': 0.9998174575367955, 'FNR': 3.638370252684814e-05, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.91      0.00      0.00    339647\\n           1       0.33      1.00      0.49    164909\\n\\n    accuracy                           0.33    504556\\n   macro avg       0.62      0.50      0.25    504556\\nweighted avg       0.72      0.33      0.16    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:00:29,296 | server.py:125 | fit progress: (5, 0.8377032279968262, {'accuracy': 0.3269508183002472, 'f1s': 0.16127681668486085, 'FPR': 0.9998174575367955, 'FNR': 3.638370252684814e-05}, 1308.0608057994395)\n",
      "INFO flwr 2024-07-20 17:00:29,297 | server.py:171 | evaluate_round 5: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:00:29,299 | server.py:222 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:02:27,984 | server.py:236 | fit_round 6 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6280443668365479, 'loss': 0.658311665058136, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.660862386226654}), (489061, {'accuracy': 0.6267848014831543, 'loss': 0.6598171591758728, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6582053899765015}), (489061, {'accuracy': 0.6265864372253418, 'loss': 0.6591244339942932, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6578533053398132}), (489061, {'accuracy': 0.628232479095459, 'loss': 0.6578821539878845, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6575909852981567})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 32ms/step - accuracy: 0.3291 - loss: 0.8065\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:05:35,955 | 589012468.py:68 | ==>> scores: {'accuracy': 0.32964229936815737, 'recall': 0.32964229936815737, 'precision': 0.48259058533582505, 'f1s': 0.18417565826665444, 'FPR': 0.9804385141043496, 'FNR': 0.031714460702569294, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.56      0.02      0.04    339647\\n           1       0.32      0.97      0.49    164909\\n\\n    accuracy                           0.33    504556\\n   macro avg       0.44      0.49      0.26    504556\\nweighted avg       0.48      0.33      0.18    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:05:35,965 | server.py:125 | fit progress: (6, 0.8063144087791443, {'accuracy': 0.32964229583740234, 'f1s': 0.18417565826665444, 'FPR': 0.9804385141043496, 'FNR': 0.031714460702569294}, 1614.7280775001273)\n",
      "INFO flwr 2024-07-20 17:05:35,966 | server.py:171 | evaluate_round 6: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:05:35,968 | server.py:222 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:07:31,082 | server.py:236 | fit_round 7 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6282222270965576, 'loss': 0.6568542122840881, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6573461294174194}), (489061, {'accuracy': 0.6282549500465393, 'loss': 0.6576483845710754, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6608986258506775}), (489061, {'accuracy': 0.6256887912750244, 'loss': 0.6604032516479492, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6571058034896851}), (489061, {'accuracy': 0.6269177198410034, 'loss': 0.6574656367301941, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6573666334152222})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 32ms/step - accuracy: 0.3371 - loss: 0.7924\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:10:38,446 | 589012468.py:68 | ==>> scores: {'accuracy': 0.33750069367919516, 'recall': 0.33750069367919516, 'precision': 0.5479426668170104, 'f1s': 0.20206495640520417, 'FPR': 0.9666359484994715, 'FNR': 0.036098696857054496, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.66      0.03      0.06    339647\\n           1       0.33      0.96      0.49    164909\\n\\n    accuracy                           0.34    504556\\n   macro avg       0.49      0.50      0.28    504556\\nweighted avg       0.55      0.34      0.20    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:10:38,452 | server.py:125 | fit progress: (7, 0.792189359664917, {'accuracy': 0.3375006914138794, 'f1s': 0.20206495640520417, 'FPR': 0.9666359484994715, 'FNR': 0.036098696857054496}, 1917.2135907001793)\n",
      "INFO flwr 2024-07-20 17:10:38,453 | server.py:171 | evaluate_round 7: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:10:38,455 | server.py:222 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:12:16,992 | server.py:236 | fit_round 8 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6285187602043152, 'loss': 0.6565228700637817, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6588783860206604}), (489061, {'accuracy': 0.6282263398170471, 'loss': 0.6569130420684814, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6575798988342285}), (489061, {'accuracy': 0.6269177198410034, 'loss': 0.6571718454360962, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6571597456932068}), (489061, {'accuracy': 0.626310408115387, 'loss': 0.6580455303192139, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6693305969238281})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 30ms/step - accuracy: 0.3708 - loss: 0.7626\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:15:13,043 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3714989020049311, 'recall': 0.3714989020049311, 'precision': 0.6373076757092239, 'f1s': 0.2727507036070743, 'FPR': 0.9083195199722064, 'FNR': 0.052186357324342514, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.78      0.09      0.16    339647\\n           1       0.34      0.95      0.50    164909\\n\\n    accuracy                           0.37    504556\\n   macro avg       0.56      0.52      0.33    504556\\nweighted avg       0.64      0.37      0.27    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:15:13,051 | server.py:125 | fit progress: (8, 0.7624481916427612, {'accuracy': 0.3714989125728607, 'f1s': 0.2727507036070743, 'FPR': 0.9083195199722064, 'FNR': 0.052186357324342514}, 2191.8107431996614)\n",
      "INFO flwr 2024-07-20 17:15:13,053 | server.py:171 | evaluate_round 8: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:15:13,054 | server.py:222 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:16:57,072 | server.py:236 | fit_round 9 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6285392045974731, 'loss': 0.6565057039260864, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6586950421333313}), (489061, {'accuracy': 0.6274268627166748, 'loss': 0.657608687877655, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6592440009117126}), (489061, {'accuracy': 0.6281057000160217, 'loss': 0.656963586807251, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6576849222183228}), (489061, {'accuracy': 0.6262919902801514, 'loss': 0.6590524911880493, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6590906381607056})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 34ms/step - accuracy: 0.3277 - loss: 0.8098\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:20:22,846 | 589012468.py:68 | ==>> scores: {'accuracy': 0.32804683721925815, 'recall': 0.32804683721925815, 'precision': 0.4602698742206142, 'f1s': 0.18148668593360143, 'FPR': 0.9823139907021113, 'FNR': 0.03273320437332104, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.53      0.02      0.03    339647\\n           1       0.32      0.97      0.48    164909\\n\\n    accuracy                           0.33    504556\\n   macro avg       0.43      0.49      0.26    504556\\nweighted avg       0.46      0.33      0.18    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:20:22,857 | server.py:125 | fit progress: (9, 0.8096414804458618, {'accuracy': 0.3280468285083771, 'f1s': 0.18148668593360143, 'FPR': 0.9823139907021113, 'FNR': 0.03273320437332104}, 2501.614414599724)\n",
      "INFO flwr 2024-07-20 17:20:22,859 | server.py:171 | evaluate_round 9: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:20:22,861 | server.py:222 | fit_round 10: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:21:54,322 | server.py:236 | fit_round 10 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6283735632896423, 'loss': 0.6568342447280884, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6586505770683289}), (489061, {'accuracy': 0.6266457438468933, 'loss': 0.6574130058288574, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6561108827590942}), (489061, {'accuracy': 0.627670168876648, 'loss': 0.6568827629089355, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6578521132469177}), (489061, {'accuracy': 0.6268298029899597, 'loss': 0.6572994589805603, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6577903032302856})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 34ms/step - accuracy: 0.3326 - loss: 0.8001\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:25:17,400 | 589012468.py:68 | ==>> scores: {'accuracy': 0.33313051474960165, 'recall': 0.33313051474960165, 'precision': 0.5157741585511868, 'f1s': 0.19273565038869747, 'FPR': 0.9737845468972197, 'FNR': 0.03474643591313997, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.61      0.03      0.05    339647\\n           1       0.32      0.97      0.49    164909\\n\\n    accuracy                           0.33    504556\\n   macro avg       0.47      0.50      0.27    504556\\nweighted avg       0.52      0.33      0.19    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:25:17,407 | server.py:125 | fit progress: (10, 0.799905002117157, {'accuracy': 0.33313050866127014, 'f1s': 0.19273565038869747, 'FPR': 0.9737845468972197, 'FNR': 0.03474643591313997}, 2796.1622517993674)\n",
      "INFO flwr 2024-07-20 17:25:17,408 | server.py:171 | evaluate_round 10: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:25:17,409 | server.py:222 | fit_round 11: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:26:51,699 | server.py:236 | fit_round 11 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6314365863800049, 'loss': 0.6540824770927429, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6589295268058777}), (489061, {'accuracy': 0.6285228133201599, 'loss': 0.6561875343322754, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6589432954788208}), (489061, {'accuracy': 0.6266109943389893, 'loss': 0.6571946144104004, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6583927273750305}), (489061, {'accuracy': 0.6266171336174011, 'loss': 0.6571184992790222, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.65781170129776})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 34ms/step - accuracy: 0.3400 - loss: 0.7945\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:30:13,751 | 589012468.py:68 | ==>> scores: {'accuracy': 0.34040621853669367, 'recall': 0.34040621853669367, 'precision': 0.5699268360279601, 'f1s': 0.20698726770463285, 'FPR': 0.9630793147002623, 'FNR': 0.034534197648400024, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.69      0.04      0.07    339647\\n           1       0.33      0.97      0.49    164909\\n\\n    accuracy                           0.34    504556\\n   macro avg       0.51      0.50      0.28    504556\\nweighted avg       0.57      0.34      0.21    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:30:13,759 | server.py:125 | fit progress: (11, 0.7944086790084839, {'accuracy': 0.340406209230423, 'f1s': 0.20698726770463285, 'FPR': 0.9630793147002623, 'FNR': 0.034534197648400024}, 3092.513742899522)\n",
      "INFO flwr 2024-07-20 17:30:13,760 | server.py:171 | evaluate_round 11: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:30:13,763 | server.py:222 | fit_round 12: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:31:50,934 | server.py:236 | fit_round 12 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6268113851547241, 'loss': 0.6570237278938293, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6558727025985718}), (489061, {'accuracy': 0.6282529234886169, 'loss': 0.656402051448822, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6568969488143921}), (489061, {'accuracy': 0.6284042000770569, 'loss': 0.6571499705314636, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6595873832702637}), (489061, {'accuracy': 0.6268625259399414, 'loss': 0.6570959091186523, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6568119525909424})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 34ms/step - accuracy: 0.3435 - loss: 0.7948\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:35:11,924 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3439697476593282, 'recall': 0.3439697476593282, 'precision': 0.5899181532082431, 'f1s': 0.2137803050347138, 'FPR': 0.9579298506979305, 'FNR': 0.0342370640777641, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.72      0.04      0.08    339647\\n           1       0.33      0.97      0.49    164909\\n\\n    accuracy                           0.34    504556\\n   macro avg       0.52      0.50      0.28    504556\\nweighted avg       0.59      0.34      0.21    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:35:11,934 | server.py:125 | fit progress: (12, 0.7945657968521118, {'accuracy': 0.34396976232528687, 'f1s': 0.2137803050347138, 'FPR': 0.9579298506979305, 'FNR': 0.0342370640777641}, 3390.6860026000068)\n",
      "INFO flwr 2024-07-20 17:35:11,935 | server.py:171 | evaluate_round 12: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:35:11,937 | server.py:222 | fit_round 13: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:36:50,359 | server.py:236 | fit_round 13 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6275781393051147, 'loss': 0.6572146415710449, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6590206623077393}), (489061, {'accuracy': 0.6282529234886169, 'loss': 0.6563974022865295, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6571382880210876}), (489061, {'accuracy': 0.6267275214195251, 'loss': 0.6573198437690735, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.656208872795105}), (489061, {'accuracy': 0.6256744861602783, 'loss': 0.6575882434844971, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6568317413330078})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 32ms/step - accuracy: 0.3466 - loss: 0.7922\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:40:05,403 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3473112994395072, 'recall': 0.3473112994395072, 'precision': 0.604933935906323, 'f1s': 0.2202741476433371, 'FPR': 0.9529217098929182, 'FNR': 0.03432802333408122, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.74      0.05      0.09    339647\\n           1       0.33      0.97      0.49    164909\\n\\n    accuracy                           0.35    504556\\n   macro avg       0.53      0.51      0.29    504556\\nweighted avg       0.60      0.35      0.22    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:40:05,410 | server.py:125 | fit progress: (13, 0.7919764518737793, {'accuracy': 0.3473112881183624, 'f1s': 0.2202741476433371, 'FPR': 0.9529217098929182, 'FNR': 0.03432802333408122}, 3684.1616011997685)\n",
      "INFO flwr 2024-07-20 17:40:05,412 | server.py:171 | evaluate_round 13: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:40:05,414 | server.py:222 | fit_round 14: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:41:43,514 | server.py:236 | fit_round 14 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6269177198410034, 'loss': 0.6568255424499512, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6567130088806152}), (489061, {'accuracy': 0.6284164786338806, 'loss': 0.6561604142189026, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6585681438446045}), (489061, {'accuracy': 0.626797080039978, 'loss': 0.656894326210022, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6558775305747986}), (489061, {'accuracy': 0.6272203326225281, 'loss': 0.6572998762130737, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6569864153862})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 32ms/step - accuracy: 0.3423 - loss: 0.7982\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:44:52,709 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3427686916813991, 'recall': 0.3427686916813991, 'precision': 0.5800381984111169, 'f1s': 0.21222330302730139, 'FPR': 0.9589397227121099, 'FNR': 0.035831883038524276, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.70      0.04      0.08    339647\\n           1       0.33      0.96      0.49    164909\\n\\n    accuracy                           0.34    504556\\n   macro avg       0.52      0.50      0.28    504556\\nweighted avg       0.58      0.34      0.21    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:44:52,716 | server.py:125 | fit progress: (14, 0.7979128360748291, {'accuracy': 0.34276869893074036, 'f1s': 0.21222330302730139, 'FPR': 0.9589397227121099, 'FNR': 0.035831883038524276}, 3971.465792399831)\n",
      "INFO flwr 2024-07-20 17:44:52,718 | server.py:171 | evaluate_round 14: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:44:52,720 | server.py:222 | fit_round 15: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:46:34,247 | server.py:236 | fit_round 15 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6285759806632996, 'loss': 0.6560025215148926, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6586147546768188}), (489061, {'accuracy': 0.6267745494842529, 'loss': 0.6568876504898071, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6558942198753357}), (489061, {'accuracy': 0.6279094219207764, 'loss': 0.6562786102294922, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6575412154197693}), (489061, {'accuracy': 0.6282079219818115, 'loss': 0.656191349029541, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6569558382034302})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 30ms/step - accuracy: 0.6383 - loss: 0.6421\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-20 17:49:30,427 | 589012468.py:68 | ==>> scores: {'accuracy': 0.637620006500765, 'recall': 0.637620006500765, 'precision': 0.4570716821081682, 'f1s': 0.5264088611457926, 'FPR': 0.05483634479327066, 'FNR': 0.995797682358149, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.66      0.95      0.78    339647\\n           1       0.04      0.00      0.01    164909\\n\\n    accuracy                           0.64    504556\\n   macro avg       0.35      0.47      0.39    504556\\nweighted avg       0.46      0.64      0.53    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:49:30,433 | server.py:125 | fit progress: (15, 0.6429798603057861, {'accuracy': 0.6376200318336487, 'f1s': 0.5264088611457926, 'FPR': 0.05483634479327066, 'FNR': 0.995797682358149}, 4249.182703599334)\n",
      "INFO flwr 2024-07-20 17:49:30,435 | server.py:171 | evaluate_round 15: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:49:30,437 | server.py:222 | fit_round 16: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:51:15,976 | server.py:236 | fit_round 16 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6282222270965576, 'loss': 0.656237781047821, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6570570468902588}), (489061, {'accuracy': 0.635654866695404, 'loss': 0.6494711637496948, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6582909822463989}), (489061, {'accuracy': 0.6287273168563843, 'loss': 0.6559593081474304, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6583269834518433}), (489061, {'accuracy': 0.6269729137420654, 'loss': 0.6567373871803284, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6568344235420227})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30ms/step - accuracy: 0.4050 - loss: 0.7521\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:54:16,070 | 589012468.py:68 | ==>> scores: {'accuracy': 0.4050551375863135, 'recall': 0.4050551375863135, 'precision': 0.6536741876164732, 'f1s': 0.3384255693947583, 'FPR': 0.8460430976867159, 'FNR': 0.07778229205198019, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.80      0.15      0.26    339647\\n           1       0.35      0.92      0.50    164909\\n\\n    accuracy                           0.41    504556\\n   macro avg       0.57      0.54      0.38    504556\\nweighted avg       0.65      0.41      0.34    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:54:16,079 | server.py:125 | fit progress: (16, 0.7521717548370361, {'accuracy': 0.40505513548851013, 'f1s': 0.3384255693947583, 'FPR': 0.8460430976867159, 'FNR': 0.07778229205198019}, 4534.826159299351)\n",
      "INFO flwr 2024-07-20 17:54:16,080 | server.py:171 | evaluate_round 16: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:54:16,082 | server.py:222 | fit_round 17: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 17:55:45,723 | server.py:236 | fit_round 17 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6285392045974731, 'loss': 0.6559134721755981, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6582068204879761}), (489061, {'accuracy': 0.6268113851547241, 'loss': 0.6568102836608887, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6559257507324219}), (489061, {'accuracy': 0.6268808841705322, 'loss': 0.6566444635391235, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6582539677619934}), (489061, {'accuracy': 0.628038227558136, 'loss': 0.6564841866493225, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6570178866386414})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 31ms/step - accuracy: 0.3355 - loss: 0.8052\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 17:58:54,251 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3359646897470251, 'recall': 0.3359646897470251, 'precision': 0.5422775772114186, 'f1s': 0.19769645134963973, 'FPR': 0.9702131919316231, 'FNR': 0.0334305586717523, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.65      0.03      0.06    339647\\n           1       0.33      0.97      0.49    164909\\n\\n    accuracy                           0.34    504556\\n   macro avg       0.49      0.50      0.27    504556\\nweighted avg       0.54      0.34      0.20    504556\\n'}\n",
      "INFO flwr 2024-07-20 17:58:54,262 | server.py:125 | fit progress: (17, 0.8049675822257996, {'accuracy': 0.3359646797180176, 'f1s': 0.19769645134963973, 'FPR': 0.9702131919316231, 'FNR': 0.0334305586717523}, 4813.007705499418)\n",
      "INFO flwr 2024-07-20 17:58:54,263 | server.py:171 | evaluate_round 17: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 17:58:54,267 | server.py:222 | fit_round 18: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 18:00:28,696 | server.py:236 | fit_round 18 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6285392045974731, 'loss': 0.6558826565742493, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6581002473831177}), (489061, {'accuracy': 0.6268113851547241, 'loss': 0.6567288637161255, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6558791399002075}), (489061, {'accuracy': 0.6271446943283081, 'loss': 0.6567303538322449, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6567727327346802}), (489061, {'accuracy': 0.6282529234886169, 'loss': 0.6561551690101624, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6569808721542358})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 31ms/step - accuracy: 0.3455 - loss: 0.7890\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 18:03:32,112 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3460844782343288, 'recall': 0.3460844782343288, 'precision': 0.5948963990895255, 'f1s': 0.21885042787018127, 'FPR': 0.9537902587097781, 'FNR': 0.036292743270531024, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.72      0.05      0.09    339647\\n           1       0.33      0.96      0.49    164909\\n\\n    accuracy                           0.35    504556\\n   macro avg       0.53      0.50      0.29    504556\\nweighted avg       0.59      0.35      0.22    504556\\n'}\n",
      "INFO flwr 2024-07-20 18:03:32,122 | server.py:125 | fit progress: (18, 0.7887288331985474, {'accuracy': 0.34608447551727295, 'f1s': 0.21885042787018127, 'FPR': 0.9537902587097781, 'FNR': 0.036292743270531024}, 5090.865696299821)\n",
      "INFO flwr 2024-07-20 18:03:32,124 | server.py:171 | evaluate_round 18: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 18:03:32,125 | server.py:222 | fit_round 19: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 18:05:07,736 | server.py:236 | fit_round 19 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.628177285194397, 'loss': 0.6561570167541504, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.6572343707084656}), (489061, {'accuracy': 0.6280218362808228, 'loss': 0.6565576791763306, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6592389941215515}), (489061, {'accuracy': 0.6268236637115479, 'loss': 0.6566319465637207, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.6573600172996521}), (489061, {'accuracy': 0.6267704963684082, 'loss': 0.6568250060081482, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6560644507408142})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 30ms/step - accuracy: 0.3411 - loss: 0.7879\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 18:08:16,151 | 589012468.py:68 | ==>> scores: {'accuracy': 0.3415616898817971, 'recall': 0.3415616898817971, 'precision': 0.566462492079808, 'f1s': 0.2114868326542728, 'FPR': 0.9591252094085919, 'FNR': 0.03914279996846746, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.68      0.04      0.08    339647\\n           1       0.33      0.96      0.49    164909\\n\\n    accuracy                           0.34    504556\\n   macro avg       0.50      0.50      0.28    504556\\nweighted avg       0.57      0.34      0.21    504556\\n'}\n",
      "INFO flwr 2024-07-20 18:08:16,159 | server.py:125 | fit progress: (19, 0.7876049280166626, {'accuracy': 0.3415616750717163, 'f1s': 0.2114868326542728, 'FPR': 0.9591252094085919, 'FNR': 0.03914279996846746}, 5374.901230399497)\n",
      "INFO flwr 2024-07-20 18:08:16,161 | server.py:171 | evaluate_round 19: no clients selected, cancel\n",
      "DEBUG flwr 2024-07-20 18:08:16,162 | server.py:222 | fit_round 20: strategy sampled 4 clients (out of 4)\n",
      "DEBUG flwr 2024-07-20 18:10:06,798 | server.py:236 | fit_round 20 received 4 results and 0 failures\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> weighted_average: [(489061, {'accuracy': 0.6288745403289795, 'loss': 0.6560693979263306, 'val_accuracy': 0.6256049871444702, 'val_loss': 0.6581478118896484}), (489061, {'accuracy': 0.6282570362091064, 'loss': 0.6561583280563354, 'val_accuracy': 0.6265802979469299, 'val_loss': 0.656743586063385}), (489061, {'accuracy': 0.6268113851547241, 'loss': 0.6568168997764587, 'val_accuracy': 0.6279052495956421, 'val_loss': 0.6557520031929016}), (489061, {'accuracy': 0.6273328065872192, 'loss': 0.6565094590187073, 'val_accuracy': 0.6266723275184631, 'val_loss': 0.656732976436615})]\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 31ms/step - accuracy: 0.3464 - loss: 0.7957\n",
      "\u001b[1m1971/1971\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "INFO flwr 2024-07-20 18:13:14,579 | 589012468.py:68 | ==>> scores: {'accuracy': 0.346994188950285, 'recall': 0.346994188950285, 'precision': 0.5997366725397691, 'f1s': 0.22041970252878684, 'FPR': 0.9526213980986141, 'FNR': 0.03591677834442025, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.73      0.05      0.09    339647\\n           1       0.33      0.96      0.49    164909\\n\\n    accuracy                           0.35    504556\\n   macro avg       0.53      0.51      0.29    504556\\nweighted avg       0.60      0.35      0.22    504556\\n'}\n",
      "INFO flwr 2024-07-20 18:13:14,586 | server.py:125 | fit progress: (20, 0.7953880429267883, {'accuracy': 0.34699419140815735, 'f1s': 0.22041970252878684, 'FPR': 0.9526213980986141, 'FNR': 0.03591677834442025}, 5673.3258905000985)\n",
      "INFO flwr 2024-07-20 18:13:14,588 | server.py:171 | evaluate_round 20: no clients selected, cancel\n",
      "INFO flwr 2024-07-20 18:13:14,589 | server.py:153 | FL finished in 5673.328672300093\n",
      "INFO flwr 2024-07-20 18:13:14,590 | app.py:226 | app_fit: losses_distributed []\n",
      "INFO flwr 2024-07-20 18:13:14,591 | app.py:227 | app_fit: metrics_distributed_fit {'accuracy': [(1, 0.6265915781259537), (2, 0.6177526861429214), (3, 0.6249859482049942), (4, 0.6138375401496887), (5, 0.6122743338346481), (6, 0.6274120211601257), (7, 0.6272709220647812), (8, 0.6274933069944382), (9, 0.6275909394025803), (10, 0.6273798197507858), (11, 0.6282968819141388), (12, 0.6275827586650848), (13, 0.6270582675933838), (14, 0.6273379027843475), (15, 0.6278669685125351), (16, 0.6298943310976028), (17, 0.6275674253702164), (18, 0.6276870518922806), (19, 0.627448320388794), (20, 0.6278189420700073)], 'loss': [(1, 1.1949312686920166), (2, 0.685820147395134), (3, 0.6716232150793076), (4, 0.6782524287700653), (5, 0.6780949980020523), (6, 0.6587838530540466), (7, 0.6580928713083267), (8, 0.6571633219718933), (9, 0.6575326174497604), (10, 0.6571073681116104), (11, 0.6561457812786102), (12, 0.6569179147481918), (13, 0.6571300327777863), (14, 0.6567950397729874), (15, 0.6563400328159332), (16, 0.6546014100313187), (17, 0.6564631015062332), (18, 0.6563742607831955), (19, 0.6565429121255875), (20, 0.656388521194458)], 'val_accuracy': [(1, 0.6266907155513763), (2, 0.6154929101467133), (3, 0.6266907155513763), (4, 0.6044331192970276), (5, 0.6162105947732925), (6, 0.6266907155513763), (7, 0.6266907155513763), (8, 0.6266907155513763), (9, 0.6266907155513763), (10, 0.6266907155513763), (11, 0.6266907155513763), (12, 0.6266907155513763), (13, 0.6266907155513763), (14, 0.6266907155513763), (15, 0.6266907155513763), (16, 0.6266907155513763), (17, 0.6266907155513763), (18, 0.6266907155513763), (19, 0.6266907155513763), (20, 0.6266907155513763)], 'val_loss': [(1, 0.7411395162343979), (2, 0.6857592314481735), (3, 0.6707460433244705), (4, 0.687263235449791), (5, 0.6687365919351578), (6, 0.6586280167102814), (7, 0.658179298043251), (8, 0.660737156867981), (9, 0.6586786508560181), (10, 0.6576009690761566), (11, 0.6585193127393723), (12, 0.6572922468185425), (13, 0.6572998911142349), (14, 0.6570362746715546), (15, 0.6572515070438385), (16, 0.6576273590326309), (17, 0.6573511064052582), (18, 0.6569332480430603), (19, 0.6574744582176208), (20, 0.6568440943956375)]}\n",
      "INFO flwr 2024-07-20 18:13:14,593 | app.py:228 | app_fit: metrics_distributed {}\n",
      "INFO flwr 2024-07-20 18:13:14,594 | app.py:229 | app_fit: losses_centralized [(0, 3.124509572982788), (1, 0.8000199794769287), (2, 0.8274058103561401), (3, 0.7539950609207153), (4, 0.8613170981407166), (5, 0.8377032279968262), (6, 0.8063144087791443), (7, 0.792189359664917), (8, 0.7624481916427612), (9, 0.8096414804458618), (10, 0.799905002117157), (11, 0.7944086790084839), (12, 0.7945657968521118), (13, 0.7919764518737793), (14, 0.7979128360748291), (15, 0.6429798603057861), (16, 0.7521717548370361), (17, 0.8049675822257996), (18, 0.7887288331985474), (19, 0.7876049280166626), (20, 0.7953880429267883)]\n",
      "INFO flwr 2024-07-20 18:13:14,595 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.42202848196029663), (1, 0.4963274598121643), (2, 0.3268398344516754), (3, 0.327666312456131), (4, 0.35416483879089355), (5, 0.3269508183002472), (6, 0.32964229583740234), (7, 0.3375006914138794), (8, 0.3714989125728607), (9, 0.3280468285083771), (10, 0.33313050866127014), (11, 0.340406209230423), (12, 0.34396976232528687), (13, 0.3473112881183624), (14, 0.34276869893074036), (15, 0.6376200318336487), (16, 0.40505513548851013), (17, 0.3359646797180176), (18, 0.34608447551727295), (19, 0.3415616750717163), (20, 0.34699419140815735)], 'f1s': [(0, 0.416052114953504), (1, 0.5116518589793133), (2, 0.16102060725869183), (3, 0.179989161923902), (4, 0.233832939350527), (5, 0.16127681668486085), (6, 0.18417565826665444), (7, 0.20206495640520417), (8, 0.2727507036070743), (9, 0.18148668593360143), (10, 0.19273565038869747), (11, 0.20698726770463285), (12, 0.2137803050347138), (13, 0.2202741476433371), (14, 0.21222330302730139), (15, 0.5264088611457926), (16, 0.3384255693947583), (17, 0.19769645134963973), (18, 0.21885042787018127), (19, 0.2114868326542728), (20, 0.22041970252878684)], 'FPR': [(0, 0.7070546773561963), (1, 0.48182377586140906), (2, 1.0), (3, 0.98354762444538), (4, 0.9422135334626833), (5, 0.9998174575367955), (6, 0.9804385141043496), (7, 0.9666359484994715), (8, 0.9083195199722064), (9, 0.9823139907021113), (10, 0.9737845468972197), (11, 0.9630793147002623), (12, 0.9579298506979305), (13, 0.9529217098929182), (14, 0.9589397227121099), (15, 0.05483634479327066), (16, 0.8460430976867159), (17, 0.9702131919316231), (18, 0.9537902587097781), (19, 0.9591252094085919), (20, 0.9526213980986141)], 'FNR': [(0, 0.3121115281761456), (1, 0.548672298055291), (2, 0.0), (3, 0.03135668762772196), (4, 0.035413470459465524), (5, 3.638370252684814e-05), (6, 0.031714460702569294), (7, 0.036098696857054496), (8, 0.052186357324342514), (9, 0.03273320437332104), (10, 0.03474643591313997), (11, 0.034534197648400024), (12, 0.0342370640777641), (13, 0.03432802333408122), (14, 0.035831883038524276), (15, 0.995797682358149), (16, 0.07778229205198019), (17, 0.0334305586717523), (18, 0.036292743270531024), (19, 0.03914279996846746), (20, 0.03591677834442025)]}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from math import floor\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=generate_client_fn(),  # a function that spawns a particular client\n",
    "    # num_clients=cfg.n_clients,  # total number of clients\n",
    "    num_clients=len(client_data),  # total number of clients\n",
    "    config=fl.server.ServerConfig(\n",
    "        num_rounds=cfg.n_rounds\n",
    "        # num_rounds=5\n",
    "    ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "    strategy=strategy,  # our strategy of choice\n",
    "    client_resources={\n",
    "        \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "        \"num_gpus\": 0.0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> history: History (loss, centralized):\n",
      "\tround 0: 3.124509572982788\n",
      "\tround 1: 0.8000199794769287\n",
      "\tround 2: 0.8274058103561401\n",
      "\tround 3: 0.7539950609207153\n",
      "\tround 4: 0.8613170981407166\n",
      "\tround 5: 0.8377032279968262\n",
      "\tround 6: 0.8063144087791443\n",
      "\tround 7: 0.792189359664917\n",
      "\tround 8: 0.7624481916427612\n",
      "\tround 9: 0.8096414804458618\n",
      "\tround 10: 0.799905002117157\n",
      "\tround 11: 0.7944086790084839\n",
      "\tround 12: 0.7945657968521118\n",
      "\tround 13: 0.7919764518737793\n",
      "\tround 14: 0.7979128360748291\n",
      "\tround 15: 0.6429798603057861\n",
      "\tround 16: 0.7521717548370361\n",
      "\tround 17: 0.8049675822257996\n",
      "\tround 18: 0.7887288331985474\n",
      "\tround 19: 0.7876049280166626\n",
      "\tround 20: 0.7953880429267883\n",
      "History (metrics, distributed, fit):\n",
      "{'accuracy': [(1, 0.6265915781259537), (2, 0.6177526861429214), (3, 0.6249859482049942), (4, 0.6138375401496887), (5, 0.6122743338346481), (6, 0.6274120211601257), (7, 0.6272709220647812), (8, 0.6274933069944382), (9, 0.6275909394025803), (10, 0.6273798197507858), (11, 0.6282968819141388), (12, 0.6275827586650848), (13, 0.6270582675933838), (14, 0.6273379027843475), (15, 0.6278669685125351), (16, 0.6298943310976028), (17, 0.6275674253702164), (18, 0.6276870518922806), (19, 0.627448320388794), (20, 0.6278189420700073)], 'loss': [(1, 1.1949312686920166), (2, 0.685820147395134), (3, 0.6716232150793076), (4, 0.6782524287700653), (5, 0.6780949980020523), (6, 0.6587838530540466), (7, 0.6580928713083267), (8, 0.6571633219718933), (9, 0.6575326174497604), (10, 0.6571073681116104), (11, 0.6561457812786102), (12, 0.6569179147481918), (13, 0.6571300327777863), (14, 0.6567950397729874), (15, 0.6563400328159332), (16, 0.6546014100313187), (17, 0.6564631015062332), (18, 0.6563742607831955), (19, 0.6565429121255875), (20, 0.656388521194458)], 'val_accuracy': [(1, 0.6266907155513763), (2, 0.6154929101467133), (3, 0.6266907155513763), (4, 0.6044331192970276), (5, 0.6162105947732925), (6, 0.6266907155513763), (7, 0.6266907155513763), (8, 0.6266907155513763), (9, 0.6266907155513763), (10, 0.6266907155513763), (11, 0.6266907155513763), (12, 0.6266907155513763), (13, 0.6266907155513763), (14, 0.6266907155513763), (15, 0.6266907155513763), (16, 0.6266907155513763), (17, 0.6266907155513763), (18, 0.6266907155513763), (19, 0.6266907155513763), (20, 0.6266907155513763)], 'val_loss': [(1, 0.7411395162343979), (2, 0.6857592314481735), (3, 0.6707460433244705), (4, 0.687263235449791), (5, 0.6687365919351578), (6, 0.6586280167102814), (7, 0.658179298043251), (8, 0.660737156867981), (9, 0.6586786508560181), (10, 0.6576009690761566), (11, 0.6585193127393723), (12, 0.6572922468185425), (13, 0.6572998911142349), (14, 0.6570362746715546), (15, 0.6572515070438385), (16, 0.6576273590326309), (17, 0.6573511064052582), (18, 0.6569332480430603), (19, 0.6574744582176208), (20, 0.6568440943956375)]}History (metrics, centralized):\n",
      "{'accuracy': [(0, 0.42202848196029663), (1, 0.4963274598121643), (2, 0.3268398344516754), (3, 0.327666312456131), (4, 0.35416483879089355), (5, 0.3269508183002472), (6, 0.32964229583740234), (7, 0.3375006914138794), (8, 0.3714989125728607), (9, 0.3280468285083771), (10, 0.33313050866127014), (11, 0.340406209230423), (12, 0.34396976232528687), (13, 0.3473112881183624), (14, 0.34276869893074036), (15, 0.6376200318336487), (16, 0.40505513548851013), (17, 0.3359646797180176), (18, 0.34608447551727295), (19, 0.3415616750717163), (20, 0.34699419140815735)], 'f1s': [(0, 0.416052114953504), (1, 0.5116518589793133), (2, 0.16102060725869183), (3, 0.179989161923902), (4, 0.233832939350527), (5, 0.16127681668486085), (6, 0.18417565826665444), (7, 0.20206495640520417), (8, 0.2727507036070743), (9, 0.18148668593360143), (10, 0.19273565038869747), (11, 0.20698726770463285), (12, 0.2137803050347138), (13, 0.2202741476433371), (14, 0.21222330302730139), (15, 0.5264088611457926), (16, 0.3384255693947583), (17, 0.19769645134963973), (18, 0.21885042787018127), (19, 0.2114868326542728), (20, 0.22041970252878684)], 'FPR': [(0, 0.7070546773561963), (1, 0.48182377586140906), (2, 1.0), (3, 0.98354762444538), (4, 0.9422135334626833), (5, 0.9998174575367955), (6, 0.9804385141043496), (7, 0.9666359484994715), (8, 0.9083195199722064), (9, 0.9823139907021113), (10, 0.9737845468972197), (11, 0.9630793147002623), (12, 0.9579298506979305), (13, 0.9529217098929182), (14, 0.9589397227121099), (15, 0.05483634479327066), (16, 0.8460430976867159), (17, 0.9702131919316231), (18, 0.9537902587097781), (19, 0.9591252094085919), (20, 0.9526213980986141)], 'FNR': [(0, 0.3121115281761456), (1, 0.548672298055291), (2, 0.0), (3, 0.03135668762772196), (4, 0.035413470459465524), (5, 3.638370252684814e-05), (6, 0.031714460702569294), (7, 0.036098696857054496), (8, 0.052186357324342514), (9, 0.03273320437332104), (10, 0.03474643591313997), (11, 0.034534197648400024), (12, 0.0342370640777641), (13, 0.03432802333408122), (14, 0.035831883038524276), (15, 0.995797682358149), (16, 0.07778229205198019), (17, 0.0334305586717523), (18, 0.036292743270531024), (19, 0.03914279996846746), (20, 0.03591677834442025)]}\n",
      "==>> end of history\n"
     ]
    }
   ],
   "source": [
    "print(f\"==>> history: {history}\")\n",
    "print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the directories if they don't exist\n",
    "if not os.path.isdir('./results'):\n",
    "    os.mkdir('./results')\n",
    "\n",
    "# creating the directories if they don't exist\n",
    "if not os.path.isdir('./results/{}'.format(dtime)):\n",
    "    os.mkdir('./results/{}'.format(dtime))\n",
    "\n",
    "# if not os.path.isdir('./results/{}'.format(dataset_name)):\n",
    "#     os.mkdir('./results/{}'.format(dataset_name))\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "filename = ('./results/{}/baseline.json'.format(dtime))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities - DiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>src_closeness</th>\n",
       "      <th>dst_closeness</th>\n",
       "      <th>src_pagerank</th>\n",
       "      <th>dst_pagerank</th>\n",
       "      <th>src_k_core</th>\n",
       "      <th>dst_k_core</th>\n",
       "      <th>src_k_truss</th>\n",
       "      <th>dst_k_truss</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990077</th>\n",
       "      <td>192.168.10.3-192.168.10.15-53-49562-17</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>49562.0</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6/7/2017 9:14</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269812</td>\n",
       "      <td>0.330023</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998033</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.804361</td>\n",
       "      <td>1.035832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524372</th>\n",
       "      <td>172.16.0.1-192.168.10.50-41262-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>41262.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5/7/2017 10:52</td>\n",
       "      <td>98685922.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.330141</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>-0.474735</td>\n",
       "      <td>-1.353992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775503</th>\n",
       "      <td>192.168.10.15-199.102.234.32-50685-443-6</td>\n",
       "      <td>199.102.234.32</td>\n",
       "      <td>443.0</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>50685.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7/7/2017 9:44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245913</td>\n",
       "      <td>0.269812</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.998033</td>\n",
       "      <td>-3.171998</td>\n",
       "      <td>2.284859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83047</th>\n",
       "      <td>192.168.10.5-69.16.175.42-51022-80-6</td>\n",
       "      <td>192.168.10.5</td>\n",
       "      <td>51022.0</td>\n",
       "      <td>69.16.175.42</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5/7/2017 10:51</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276961</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.044805</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>2.696235</td>\n",
       "      <td>1.922592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845324</th>\n",
       "      <td>192.168.10.3-192.168.10.15-53-54495-17</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>54495.0</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>03/07/2017 11:32:17</td>\n",
       "      <td>30679.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269812</td>\n",
       "      <td>0.330023</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998033</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.804361</td>\n",
       "      <td>1.035832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210570</th>\n",
       "      <td>172.16.0.1-192.168.10.50-58284-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>58284.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5/7/2017 11:01</td>\n",
       "      <td>31606378.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.330141</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>-0.474735</td>\n",
       "      <td>-1.353992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578917</th>\n",
       "      <td>192.168.10.8-192.168.10.14-33265-6668-6</td>\n",
       "      <td>192.168.10.8</td>\n",
       "      <td>33265.0</td>\n",
       "      <td>192.168.10.14</td>\n",
       "      <td>6668.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6/7/2017 3:19</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355021</td>\n",
       "      <td>0.270038</td>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025574</td>\n",
       "      <td>-2.095889</td>\n",
       "      <td>3.381614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98330</th>\n",
       "      <td>192.168.10.3-192.168.10.16-53-10134-17</td>\n",
       "      <td>192.168.10.16</td>\n",
       "      <td>10134.0</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4/7/2017 10:52</td>\n",
       "      <td>64770.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279784</td>\n",
       "      <td>0.330023</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.489836</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.699324</td>\n",
       "      <td>0.893982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178177</th>\n",
       "      <td>172.16.0.1-192.168.10.50-38556-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>38556.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7/7/2017 4:13</td>\n",
       "      <td>1286154.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.330141</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>-0.474735</td>\n",
       "      <td>-1.353992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629128</th>\n",
       "      <td>172.16.0.1-192.168.10.50-57214-80-6</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>57214.0</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5/7/2017 10:57</td>\n",
       "      <td>98669673.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.330141</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>-0.474735</td>\n",
       "      <td>-1.353992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504556 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Flow ID          Src IP  Src Port  \\\n",
       "990077     192.168.10.3-192.168.10.15-53-49562-17   192.168.10.15   49562.0   \n",
       "1524372       172.16.0.1-192.168.10.50-41262-80-6      172.16.0.1   41262.0   \n",
       "775503   192.168.10.15-199.102.234.32-50685-443-6  199.102.234.32     443.0   \n",
       "83047        192.168.10.5-69.16.175.42-51022-80-6    192.168.10.5   51022.0   \n",
       "845324     192.168.10.3-192.168.10.15-53-54495-17   192.168.10.15   54495.0   \n",
       "...                                           ...             ...       ...   \n",
       "1210570       172.16.0.1-192.168.10.50-58284-80-6      172.16.0.1   58284.0   \n",
       "578917    192.168.10.8-192.168.10.14-33265-6668-6    192.168.10.8   33265.0   \n",
       "98330      192.168.10.3-192.168.10.16-53-10134-17   192.168.10.16   10134.0   \n",
       "1178177       172.16.0.1-192.168.10.50-38556-80-6      172.16.0.1   38556.0   \n",
       "629128        172.16.0.1-192.168.10.50-57214-80-6      172.16.0.1   57214.0   \n",
       "\n",
       "                Dst IP  Dst Port  Protocol            Timestamp  \\\n",
       "990077    192.168.10.3      53.0      17.0        6/7/2017 9:14   \n",
       "1524372  192.168.10.50      80.0       6.0       5/7/2017 10:52   \n",
       "775503   192.168.10.15   50685.0       6.0        7/7/2017 9:44   \n",
       "83047     69.16.175.42      80.0       6.0       5/7/2017 10:51   \n",
       "845324    192.168.10.3      53.0      17.0  03/07/2017 11:32:17   \n",
       "...                ...       ...       ...                  ...   \n",
       "1210570  192.168.10.50      80.0       6.0       5/7/2017 11:01   \n",
       "578917   192.168.10.14    6668.0       6.0        6/7/2017 3:19   \n",
       "98330     192.168.10.3      53.0      17.0       4/7/2017 10:52   \n",
       "1178177  192.168.10.50      80.0       6.0        7/7/2017 4:13   \n",
       "629128   192.168.10.50      80.0       6.0       5/7/2017 10:57   \n",
       "\n",
       "         Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  ...  src_closeness  \\\n",
       "990077           287.0           2.0           2.0  ...       0.269812   \n",
       "1524372     98685922.0           9.0           5.0  ...       0.242793   \n",
       "775503             3.0           2.0           0.0  ...       0.245913   \n",
       "83047             82.0           2.0           0.0  ...       0.276961   \n",
       "845324         30679.0           4.0           2.0  ...       0.269812   \n",
       "...                ...           ...           ...  ...            ...   \n",
       "1210570     31606378.0           2.0           2.0  ...       0.242793   \n",
       "578917            48.0           2.0           0.0  ...       0.355021   \n",
       "98330          64770.0           2.0           2.0  ...       0.279784   \n",
       "1178177      1286154.0           5.0           0.0  ...       0.242793   \n",
       "629128      98669673.0           7.0           6.0  ...       0.242793   \n",
       "\n",
       "         dst_closeness  src_pagerank  dst_pagerank  src_k_core  dst_k_core  \\\n",
       "990077        0.330023      0.036407      0.000414    1.000000    1.000000   \n",
       "1524372       0.330141      0.000052      0.000454    0.565217    1.000000   \n",
       "775503        0.269812      0.000071      0.036407    0.434783    1.000000   \n",
       "83047         0.310900      0.044805      0.000102    1.000000    0.695652   \n",
       "845324        0.330023      0.036407      0.000414    1.000000    1.000000   \n",
       "...                ...           ...           ...         ...         ...   \n",
       "1210570       0.330141      0.000052      0.000454    0.565217    1.000000   \n",
       "578917        0.270038      0.033772      0.036593    1.000000    1.000000   \n",
       "98330         0.330023      0.036047      0.000414    1.000000    1.000000   \n",
       "1178177       0.330141      0.000052      0.000454    0.565217    1.000000   \n",
       "629128        0.330141      0.000052      0.000454    0.565217    1.000000   \n",
       "\n",
       "         src_k_truss  dst_k_truss     pca_1     pca_2  \n",
       "990077      0.998033     0.019672  0.804361  1.035832  \n",
       "1524372     0.006557     0.035410 -0.474735 -1.353992  \n",
       "775503      0.003934     0.998033 -3.171998  2.284859  \n",
       "83047       1.000000     0.006557  2.696235  1.922592  \n",
       "845324      0.998033     0.019672  0.804361  1.035832  \n",
       "...              ...          ...       ...       ...  \n",
       "1210570     0.006557     0.035410 -0.474735 -1.353992  \n",
       "578917      1.000000     0.025574 -2.095889  3.381614  \n",
       "98330       0.489836     0.019672  0.699324  0.893982  \n",
       "1178177     0.006557     0.035410 -0.474735 -1.353992  \n",
       "629128      0.006557     0.035410 -0.474735 -1.353992  \n",
       "\n",
       "[504556 rows x 101 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['src_multidigraph_degree', 'dst_multidigraph_degree', 'src_multidigraph_betweenness', 'dst_multidigraph_betweenness', 'src_multidigraph_pagerank', 'dst_multidigraph_pagerank'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     test[dataset\u001b[39m.\u001b[39mlabel_col] \u001b[39m=\u001b[39m test[dataset\u001b[39m.\u001b[39mclass_num_col]\n\u001b[0;32m      6\u001b[0m \u001b[39m# test.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m test\u001b[39m.\u001b[39;49mdrop([\u001b[39m\"\u001b[39;49m\u001b[39msrc_multidigraph_degree\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdst_multidigraph_degree\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msrc_multidigraph_betweenness\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdst_multidigraph_betweenness\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msrc_multidigraph_pagerank\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdst_multidigraph_pagerank\u001b[39;49m\u001b[39m\"\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      9\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cfg\u001b[39m.\u001b[39mmulti_class:\n\u001b[0;32m     10\u001b[0m     test_by_class \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5569\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5570\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5571\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5572\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5573\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5574\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5575\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5576\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4783\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4784\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4785\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4787\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4788\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4825\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4826\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4827\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4828\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4830\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4831\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrateur\\Desktop\\centralities-with-fl-nids-main\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['src_multidigraph_degree', 'dst_multidigraph_degree', 'src_multidigraph_betweenness', 'dst_multidigraph_betweenness', 'src_multidigraph_pagerank', 'dst_multidigraph_pagerank'] not found in axis\""
     ]
    }
   ],
   "source": [
    "test = pd.read_parquet(folder_path + \"test.parquet\")\n",
    "\n",
    "if cfg.multi_class:\n",
    "    test[dataset.label_col] = test[dataset.class_num_col]\n",
    "    \n",
    "# test.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\n",
    "test.drop([\"src_multidigraph_degree\", \"dst_multidigraph_degree\", \"src_multidigraph_betweenness\", \"dst_multidigraph_betweenness\", \"src_multidigraph_pagerank\", \"dst_multidigraph_pagerank\"], axis=1, inplace=True)\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    test_by_class = {}\n",
    "    classes = test[dataset.class_col].unique()\n",
    "    for class_value in classes:\n",
    "        test_class = test[test[dataset.class_col] == class_value].copy()\n",
    "        test_class.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "        test_class.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "        test_class.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        test_class_labels = test_class[dataset.label_col].to_numpy()\n",
    "        test_class = test_class.drop([dataset.label_col], axis=1).to_numpy()\n",
    "\n",
    "        test_by_class[class_value] = (test_class, test_class_labels)\n",
    "    \n",
    "    \n",
    "test.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "test.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "test_labels = test[dataset.label_col].to_numpy()\n",
    "test = test.drop([dataset.label_col], axis=1).to_numpy()\n",
    "input_dim = test.shape[1]\n",
    "\n",
    "client_data = []\n",
    "for client_path in clients_paths:\n",
    "    client_data.append(pd.read_parquet(client_path))\n",
    "    \n",
    "for i in range(len(client_data)):\n",
    "    \n",
    "    cdata = client_data[i]\n",
    "    \n",
    "    if cfg.multi_class:\n",
    "        cdata[dataset.label_col] = cdata[dataset.class_num_col]\n",
    "        \n",
    "    # cdata.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\n",
    "    cdata.drop([\"src_multidigraph_degree\", \"dst_multidigraph_degree\", \"src_multidigraph_betweenness\", \"dst_multidigraph_betweenness\", \"src_multidigraph_pagerank\", \"dst_multidigraph_pagerank\"], axis=1, inplace=True)\n",
    "\n",
    "    cdata.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "    cdata.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "    cdata.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    c_train, c_test = train_test_split(cdata, test_size=0.1)\n",
    "\n",
    "    y_train = c_train[dataset.label_col].to_numpy()\n",
    "    x_train = c_train.drop([dataset.label_col], axis=1).to_numpy()\n",
    "    y_test = c_test[dataset.label_col].to_numpy()\n",
    "    x_test = c_test.drop([dataset.label_col], axis=1).to_numpy()\n",
    "    \n",
    "    client_data[i] = (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}  # a dictionary that will contain all the options and results of models\n",
    "# add all options to the results dictionary, to know what options selected for obtained results\n",
    "results[\"configuration\"] = \"2dt - Centralities - DiGraph\"\n",
    "results[\"dtime\"] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "results[\"multi_class\"] = cfg.multi_class\n",
    "results[\"learning_rate\"] = learning_rate\n",
    "results[\"dataset_name\"] = dataset.name\n",
    "results[\"num_classes\"] = num_classes\n",
    "results[\"labels_names\"] = labels_names\n",
    "results[\"input_dim\"] = input_dim\n",
    "\n",
    "results[\"scores\"] = {}\n",
    "results[\"scores\"][\"server\"] = {}\n",
    "results[\"scores\"][\"clients\"] = {}\n",
    "results[\"scores\"][\"accuracy\"] = {}\n",
    "results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    results[\"scores\"][\"test_by_class\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "    for k in test_by_class.keys():\n",
    "        results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_keras_model(input_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, x_train, y_train, x_test, y_test):\n",
    "        self.cid = cid\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "        self.model = create_keras_model(input_shape=input_dim)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def set_parameters(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \n",
    "        lr=float(config[\"lr\"])\n",
    "        # self.model = create_keras_model(input_shape= self.x_train.shape[1], alpha=lr)\n",
    "        self.model = create_keras_model(input_shape=input_dim, alpha=lr)\n",
    "        # log(INFO, f\"==>> config: {config}\")\n",
    "        # log(INFO, f\"==>> float(config[lr]): {lr}\")\n",
    "        self.set_parameters(parameters, config)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/digraph/client_{}\".format(dtime, self.cid)\n",
    "        tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        history = self.model.fit(self.x_train, self.y_train,\n",
    "                                 epochs=config[\"local_epochs\"],\n",
    "                                 batch_size=config[\"batch_size\"],\n",
    "                                 validation_data=(self.x_test, self.y_test),\n",
    "                                 verbose=0,\n",
    "                                 callbacks=[tensorboard_callback])\n",
    "\n",
    "        return self.get_parameters(config), len(self.x_train), {k: v[-1] for k, v in history.history.items()}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test, cfg.config_fit.batch_size, verbose=0)\n",
    "        return loss, len(self.x_test), {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn():\n",
    "    def client_fn(cid: str):\n",
    "        i = int(cid)\n",
    "        return FLClient(cid, client_data[i][0], client_data[i][1], client_data[i][2], client_data[i][3]).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_fit_config(config: DictConfig):\n",
    "\n",
    "    def fit_config_fn(server_round: int):\n",
    "        alpha = learning_rate\n",
    "        if server_round > 5:\n",
    "            alpha = alpha / (1 + 0.5 * server_round)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"lr\": alpha,\n",
    "            \"local_epochs\": config.local_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "        }\n",
    "\n",
    "    return fit_config_fn\n",
    "\n",
    "\n",
    "def get_evaluate_fn(x_test_sever, y_test_server):\n",
    "\n",
    "    def evaluate_fn(server_round: int, parameters, config):\n",
    "        # eval_model = model\n",
    "        eval_model = create_keras_model(input_shape=input_dim)\n",
    "        eval_model.set_weights(parameters)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/digraph/server\".format(dtime) \n",
    "        # logdir = \"logs/scalars/client{}_\".format(config[\"cid\"]) + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        test_loss, test_acc = eval_model.evaluate(x_test_sever, y_test_server,\n",
    "                                                  batch_size = cfg.config_fit.batch_size,\n",
    "                                                  callbacks=[tensorboard_callback])\n",
    "        \n",
    "        \n",
    "        y_pred = eval_model.predict(x_test_sever, batch_size = cfg.config_fit.batch_size)\n",
    "        \n",
    "        if cfg.multi_class:\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            scores = custom_acc_mc(y_test_server, y_pred)\n",
    "        else:\n",
    "            y_pred = np.transpose(y_pred)[0]\n",
    "            y_pred = list(\n",
    "                map(lambda x: 0 if x < 0.5 else 1, y_pred))\n",
    "            scores = custom_acc_binary(y_test_server, y_pred)\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        results_final[\"centralities - DiGraph\"][\"accuracy\"][server_round] = scores[\"accuracy\"]\n",
    "        results_final[\"centralities - DiGraph\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        \n",
    "        if not cfg.multi_class:\n",
    "            for k in test_by_class.keys():\n",
    "                y_pred_class = eval_model.predict(test_by_class[k][0], batch_size = cfg.config_fit.batch_size, verbose = 0)\n",
    "                y_pred_class = np.transpose(y_pred_class)[0]\n",
    "                y_pred_class = list(map(lambda x: 0 if x < 0.5 else 1, y_pred_class))\n",
    "                scores_class = custom_acc_binary(test_by_class[k][1], y_pred_class)\n",
    "                results[\"scores\"][\"test_by_class\"][\"accuracy\"][k][server_round] = scores_class[\"accuracy\"]\n",
    "                results[\"scores\"][\"test_by_class\"][\"f1s\"][k][server_round] = scores_class[\"f1s\"]\n",
    "                \n",
    "        log(INFO, f\"==>> scores: {scores}\")\n",
    "        \n",
    "        \n",
    "        return test_loss, {\"accuracy\": test_acc, \"f1s\": scores[\"f1s\"], \"FPR\": scores[\"FPR\"], \"FNR\": scores[\"FNR\"]}\n",
    "\n",
    "    return evaluate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics):\n",
    "    print(f\"==>> weighted_average: {metrics}\")\n",
    "\n",
    "    total_examples = 0\n",
    "    federated_metrics = {k: 0 for k in metrics[0][1].keys()}\n",
    "    for num_examples, m in metrics:\n",
    "        for k, v in m.items():\n",
    "            federated_metrics[k] += num_examples * v\n",
    "        total_examples += num_examples\n",
    "    return {k: v / total_examples for k, v in federated_metrics.items()}\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "    min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "    fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "    min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "    min_available_clients=len(client_data),  # total clients in the simulation\n",
    "    fit_metrics_aggregation_fn = weighted_average,\n",
    "    # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "    on_fit_config_fn=get_on_fit_config(\n",
    "        cfg.config_fit\n",
    "    ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "    evaluate_fn=get_evaluate_fn(test, test_labels),\n",
    ")  # a function to run on the server side to evaluate the global model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from math import floor\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=generate_client_fn(),  # a function that spawns a particular client\n",
    "    # num_clients=cfg.n_clients,  # total number of clients\n",
    "    num_clients=len(client_data),  # total number of clients\n",
    "    config=fl.server.ServerConfig(\n",
    "        num_rounds=cfg.n_rounds\n",
    "        # num_rounds=5\n",
    "    ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "    strategy=strategy,  # our strategy of choice\n",
    "    client_resources={\n",
    "        \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "        \"num_gpus\": 0.0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==>> history: {history}\")\n",
    "print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ('./results/{}/digraph.json'.format(dtime))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities - MultiDiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(folder_path + \"test.parquet\")\n",
    "\n",
    "if cfg.multi_class:\n",
    "    test[dataset.label_col] = test[dataset.class_num_col]\n",
    "    \n",
    "test.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\n",
    "# test.drop([\"src_multidigraph_degree\", \"dst_multidigraph_degree\", \"src_multidigraph_betweenness\", \"dst_multidigraph_betweenness\", \"src_multidigraph_pagerank\", \"dst_multidigraph_pagerank\"], axis=1, inplace=True)\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    test_by_class = {}\n",
    "    classes = test[dataset.class_col].unique()\n",
    "    for class_value in classes:\n",
    "        test_class = test[test[dataset.class_col] == class_value].copy()\n",
    "        test_class.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "        test_class.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "        test_class.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        test_class_labels = test_class[dataset.label_col].to_numpy()\n",
    "        test_class = test_class.drop([dataset.label_col], axis=1).to_numpy()\n",
    "\n",
    "        test_by_class[class_value] = (test_class, test_class_labels)\n",
    "    \n",
    "    \n",
    "test.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "test.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "test_labels = test[dataset.label_col].to_numpy()\n",
    "test = test.drop([dataset.label_col], axis=1).to_numpy()\n",
    "input_dim = test.shape[1]\n",
    "\n",
    "client_data = []\n",
    "for client_path in clients_paths:\n",
    "    client_data.append(pd.read_parquet(client_path))\n",
    "    \n",
    "for i in range(len(client_data)):\n",
    "    \n",
    "    cdata = client_data[i]\n",
    "    \n",
    "    if cfg.multi_class:\n",
    "        cdata[dataset.label_col] = cdata[dataset.class_num_col]\n",
    "        \n",
    "    cdata.drop([\"src_degree\", \"dst_degree\", \"src_betweenness\", \"dst_betweenness\", \"src_pagerank\", \"dst_pagerank\"], axis=1, inplace=True)\n",
    "    # cdata.drop([\"src_multidigraph_degree\", \"dst_multidigraph_degree\", \"src_multidigraph_betweenness\", \"dst_multidigraph_betweenness\", \"src_multidigraph_pagerank\", \"dst_multidigraph_pagerank\"], axis=1, inplace=True)\n",
    "\n",
    "    cdata.drop(dataset.drop_columns, axis=1, inplace=True)\n",
    "    cdata.drop(dataset.weak_columns, axis=1, inplace=True)\n",
    "    cdata.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    c_train, c_test = train_test_split(cdata, test_size=0.1)\n",
    "\n",
    "    y_train = c_train[dataset.label_col].to_numpy()\n",
    "    x_train = c_train.drop([dataset.label_col], axis=1).to_numpy()\n",
    "    y_test = c_test[dataset.label_col].to_numpy()\n",
    "    x_test = c_test.drop([dataset.label_col], axis=1).to_numpy()\n",
    "    \n",
    "    client_data[i] = (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}  # a dictionary that will contain all the options and results of models\n",
    "# add all options to the results dictionary, to know what options selected for obtained results\n",
    "results[\"configuration\"] = \"2dt - Centralities - MultiDiGraph\"\n",
    "results[\"dtime\"] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "results[\"multi_class\"] = cfg.multi_class\n",
    "results[\"learning_rate\"] = learning_rate\n",
    "results[\"dataset_name\"] = dataset.name\n",
    "results[\"num_classes\"] = num_classes\n",
    "results[\"labels_names\"] = labels_names\n",
    "results[\"input_dim\"] = input_dim\n",
    "\n",
    "results[\"scores\"] = {}\n",
    "results[\"scores\"][\"server\"] = {}\n",
    "results[\"scores\"][\"clients\"] = {}\n",
    "results[\"scores\"][\"accuracy\"] = {}\n",
    "results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    results[\"scores\"][\"test_by_class\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "    for k in test_by_class.keys():\n",
    "        results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_keras_model(input_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, x_train, y_train, x_test, y_test):\n",
    "        self.cid = cid\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "        self.model = create_keras_model(input_shape=input_dim)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def set_parameters(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \n",
    "        lr=float(config[\"lr\"])\n",
    "        # self.model = create_keras_model(input_shape= self.x_train.shape[1], alpha=lr)\n",
    "        self.model = create_keras_model(input_shape=input_dim, alpha=lr)\n",
    "        # log(INFO, f\"==>> config: {config}\")\n",
    "        # log(INFO, f\"==>> float(config[lr]): {lr}\")\n",
    "        self.set_parameters(parameters, config)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/multidigraph/client_{}\".format(dtime, self.cid)\n",
    "        tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        history = self.model.fit(self.x_train, self.y_train,\n",
    "                                 epochs=config[\"local_epochs\"],\n",
    "                                 batch_size=config[\"batch_size\"],\n",
    "                                 validation_data=(self.x_test, self.y_test),\n",
    "                                 verbose=0,\n",
    "                                 callbacks=[tensorboard_callback])\n",
    "\n",
    "        return self.get_parameters(config), len(self.x_train), {k: v[-1] for k, v in history.history.items()}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test, cfg.config_fit.batch_size, verbose=0)\n",
    "        return loss, len(self.x_test), {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn():\n",
    "    def client_fn(cid: str):\n",
    "        i = int(cid)\n",
    "        return FLClient(cid, client_data[i][0], client_data[i][1], client_data[i][2], client_data[i][3]).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_fit_config(config: DictConfig):\n",
    "\n",
    "    def fit_config_fn(server_round: int):\n",
    "        alpha = learning_rate\n",
    "        if server_round > 5:\n",
    "            alpha = alpha / (1 + 0.5 * server_round)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"lr\": alpha,\n",
    "            \"local_epochs\": config.local_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "        }\n",
    "\n",
    "    return fit_config_fn\n",
    "\n",
    "\n",
    "def get_evaluate_fn(x_test_sever, y_test_server):\n",
    "\n",
    "    def evaluate_fn(server_round: int, parameters, config):\n",
    "        # eval_model = model\n",
    "        eval_model = create_keras_model(input_shape=input_dim)\n",
    "        eval_model.set_weights(parameters)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/multidigraph/server\".format(dtime) \n",
    "        # logdir = \"logs/scalars/client{}_\".format(config[\"cid\"]) + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "        test_loss, test_acc = eval_model.evaluate(x_test_sever, y_test_server,\n",
    "                                                  batch_size = cfg.config_fit.batch_size,\n",
    "                                                  callbacks=[tensorboard_callback])\n",
    "        \n",
    "        \n",
    "        y_pred = eval_model.predict(x_test_sever, batch_size = cfg.config_fit.batch_size)\n",
    "        \n",
    "        if cfg.multi_class:\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            scores = custom_acc_mc(y_test_server, y_pred)\n",
    "        else:\n",
    "            y_pred = np.transpose(y_pred)[0]\n",
    "            y_pred = list(\n",
    "                map(lambda x: 0 if x < 0.5 else 1, y_pred))\n",
    "            scores = custom_acc_binary(y_test_server, y_pred)\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        results_final[\"centralities - MultiDiGraph\"][\"accuracy\"][server_round] = scores[\"accuracy\"]\n",
    "        results_final[\"centralities - MultiDiGraph\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        \n",
    "        if not cfg.multi_class:\n",
    "            for k in test_by_class.keys():\n",
    "                y_pred_class = eval_model.predict(test_by_class[k][0], batch_size = cfg.config_fit.batch_size, verbose = 0)\n",
    "                y_pred_class = np.transpose(y_pred_class)[0]\n",
    "                y_pred_class = list(map(lambda x: 0 if x < 0.5 else 1, y_pred_class))\n",
    "                scores_class = custom_acc_binary(test_by_class[k][1], y_pred_class)\n",
    "                results[\"scores\"][\"test_by_class\"][\"accuracy\"][k][server_round] = scores_class[\"accuracy\"]\n",
    "                results[\"scores\"][\"test_by_class\"][\"f1s\"][k][server_round] = scores_class[\"f1s\"]\n",
    "                \n",
    "        log(INFO, f\"==>> scores: {scores}\")\n",
    "        \n",
    "        \n",
    "        return test_loss, {\"accuracy\": test_acc, \"f1s\": scores[\"f1s\"], \"FPR\": scores[\"FPR\"], \"FNR\": scores[\"FNR\"]}\n",
    "\n",
    "    return evaluate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics):\n",
    "    print(f\"==>> weighted_average: {metrics}\")\n",
    "\n",
    "    total_examples = 0\n",
    "    federated_metrics = {k: 0 for k in metrics[0][1].keys()}\n",
    "    for num_examples, m in metrics:\n",
    "        for k, v in m.items():\n",
    "            federated_metrics[k] += num_examples * v\n",
    "        total_examples += num_examples\n",
    "    return {k: v / total_examples for k, v in federated_metrics.items()}\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "    min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "    fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "    min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "    min_available_clients=len(client_data),  # total clients in the simulation\n",
    "    fit_metrics_aggregation_fn = weighted_average,\n",
    "    # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "    on_fit_config_fn=get_on_fit_config(\n",
    "        cfg.config_fit\n",
    "    ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "    evaluate_fn=get_evaluate_fn(test, test_labels),\n",
    ")  # a function to run on the server side to evaluate the global model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from math import floor\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=generate_client_fn(),  # a function that spawns a particular client\n",
    "    # num_clients=cfg.n_clients,  # total number of clients\n",
    "    num_clients=len(client_data),  # total number of clients\n",
    "    config=fl.server.ServerConfig(\n",
    "        num_rounds=cfg.n_rounds\n",
    "        # num_rounds=5\n",
    "    ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "    strategy=strategy,  # our strategy of choice\n",
    "    client_resources={\n",
    "        \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "        \"num_gpus\": 0.0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==>> history: {history}\")\n",
    "print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ('./results/{}/multidigraph.json'.format(dtime))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ('./results/{}/results_final.json'.format(dtime))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
